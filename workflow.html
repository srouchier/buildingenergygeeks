
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>A Bayesian data analysis workflow &#8212; Building energy probabilistic modelling</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'workflow';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Linear regression" href="b01_linearregression.html" />
    <link rel="prev" title="Simplified building energy modelling" href="modelling.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Building energy probabilistic modelling - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Building energy probabilistic modelling - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Building energy probabilistic modelling
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="background.html">Motivation for probabilistic modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelling.html">Simplified building energy modelling</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">A Bayesian data analysis workflow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Simple regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="b01_linearregression.html">Linear regression</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/srouchier/buildingenergygeeks" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/srouchier/buildingenergygeeks/issues/new?title=Issue%20on%20page%20%2Fworkflow.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/workflow.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>A Bayesian data analysis workflow</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-a-bayesian-approach">Motivation for a Bayesian approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Workflow</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-setting-up-a-probability-model">Step 1: setting up a probability model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-learning">Step 2: learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-checking-and-evaluation">Step 3: model checking and evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-analysis">Residual analysis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scoring-rules">Scoring rules</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparison-and-cross-validation">Model comparison and cross-validation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="a-bayesian-data-analysis-workflow">
<span id="workflow"></span><h1>A Bayesian data analysis workflow<a class="headerlink" href="#a-bayesian-data-analysis-workflow" title="Link to this heading">#</a></h1>
<section id="motivation-for-a-bayesian-approach">
<h2>Motivation for a Bayesian approach<a class="headerlink" href="#motivation-for-a-bayesian-approach" title="Link to this heading">#</a></h2>
<p>Bayesian statistics are mentioned in the Annex B of the ASHRAE Guideline 14, after it has been observed that standard approaches make it difficult to estimate the savings uncertainty when complex models are required in a measurement and verification worflow:</p>
<p><em>“Savings uncertainty can only be determined exactly when energy use is a linear function of some independent variable(s). For more complicated models of energy use, such as changepoint models, and for data with serially autocorrelated errors, approximate formulas must be used. These approximations provide reasonable accuracy when compared with simulated data, but in general it is difficult to determine their accuracy in any given situation. One alternative method for determining savings uncertainty to any desired degree of accuracy is to use a Bayesian approach.”</em></p>
<p>Still on the topic of measurement and verification, and the estimation of savings uncertainty, several advantages and drawbacks of Bayesian approaches are described by <span id="id1">[<a class="reference internal" href="background.html#id20" title="Herman Carstens, Xiaohua Xia, and Sarma Yadavalli. Bayesian energy measurement and verification analysis. Energies, 11(2):380, 2018.">Carstens <em>et al.</em>, 2018</a>]</span>. Advantages include:</p>
<ul class="simple">
<li><p>Because Bayesian models are probabilistic, uncertainty is automatically and exactly quantified. Confidence intervals can be interpreted in the way most people understand them: degrees of belief about the value of the parameter.</p></li>
<li><p>Bayesian models are more universal and flexible than standard methods. Models are also modular and can be designed to suit the problem. For example, it is no different to create terms for serial correlation, or heteroscedasticity (non-constant variance) than it is to specify an ordinary linear model.</p></li>
<li><p>The Bayesian approach allows for the incorporation of prior information where appropriate.</p></li>
<li><p>When the savings need to be calculated for “normalised conditions”, for example, a “typical meteorological year”, rather than the conditions during the post-retrofit monitoring period, it is not possible to quantify uncertainty using current methods. However, it can be naturally and easily quantified using the Bayesian approach.</p></li>
</ul>
<p>The first two points above are the most relevant to a data analyst: any arbitrary model structure can be defined to explain the data, and the exact same set of formulas can then be used to obtain any uncertainty after the models have been fitted.</p>
</section>
<section id="id2">
<h2>Workflow<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>This article starts with a generic tutorial on Bayesian modelling, and shows the essential steps to apply it to building energy use prediction. The following workflow, illustrated on <a class="reference internal" href="#figworkflow"><span class="std std-numref">Fig. 15</span></a>, follows the formalisation into three steps by <span id="id3">[<a class="reference internal" href="background.html#id19" title="Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian data analysis. CRC press, 2013.">Gelman <em>et al.</em>, 2013</a>]</span>. Readers interested in a more complete course are referred to this reference book, or the more introductory one of <span id="id4">[<a class="reference internal" href="background.html#id21" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman and Hall/CRC, 2018.">McElreath, 2018</a>]</span>.</p>
<figure class="align-center" id="figworkflow">
<a class="reference internal image-reference" href="_images/301_workflow.png"><img alt="_images/301_workflow.png" src="_images/301_workflow.png" style="width: 500px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Bayesian data analysis workflow</span><a class="headerlink" href="#figworkflow" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The methodology is not different from traditional inverse modelling: each candidate model is defined, calibrated, and its validity is checked. All validated models are then ranked on some model comparison metrics, until one is selected. However, Bayesian data analysis comes with probabilistic metrics at each of these steps, which offer greater insight into the reliability of our inferences.</p>
<section id="step-1-setting-up-a-probability-model">
<h3>Step 1: setting up a probability model<a class="headerlink" href="#step-1-setting-up-a-probability-model" title="Link to this heading">#</a></h3>
<p>A full probability model is defined by <span id="id5">[<a class="reference internal" href="background.html#id19" title="Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian data analysis. CRC press, 2013.">Gelman <em>et al.</em>, 2013</a>]</span> as a joint probability distribution for observable data <span class="math notranslate nohighlight">\(y\)</span> and unobservable quantities <span class="math notranslate nohighlight">\(\theta\)</span> in a problem.</p>
<div class="math notranslate nohighlight" id="equation-model01">
<span class="eqno">(2)<a class="headerlink" href="#equation-model01" title="Link to this equation">#</a></span>\[p(\theta,y) = p(\theta)p(y|\theta)\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> denote any model parameter, or unobserved quantity, about which to make probability statements. A Bayesian model is therefore defined by two components:</p>
<ul class="simple">
<li><p>An observational model <span class="math notranslate nohighlight">\(p(y|\theta)\)</span>, or likelihood function, which describes the relationship between the data <span class="math notranslate nohighlight">\(y\)</span> and the model parameters <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>A prior model <span class="math notranslate nohighlight">\(p(\theta)\)</span> which encodes eventual assumptions regarding model parameters, independently of the observed data.</p></li>
</ul>
<p>The choice of observational model is up to the expert after data visualisation. Having sensible priors is a way to incorporate scientific knowledge into the model. It can also facilitate convergence of the learning algorithm, should there be identifiability issues from a large number of parameters.</p>
<p>The full probability model is the formalization of many assumptions regarding the data-generating process. In theory, the model can be formulated only based on domain expertise, regardless of the data. In practice, a model which is inconsistent with the data has little chance to yield informative inferences after training. The prior predictive distribution, or marginal distribution of observations <span class="math notranslate nohighlight">\(p(y)\)</span>, is a way to check for the consistency of our expertise.</p>
<div class="math notranslate nohighlight" id="equation-priorpredictive">
<span class="eqno">(3)<a class="headerlink" href="#equation-priorpredictive" title="Link to this equation">#</a></span>\[p(y) = \int p(y|\theta)p(\theta) \mathrm{d}\theta\]</div>
<p>This is also called the prior predictive distribution. Computing this distribution is equivalent to running a few simulations of a numerical model before its training, by drawing parameter values from a sensible distribution <span class="math notranslate nohighlight">\(p(\theta)\)</span>. Prior predictive checks generate data according to the prior in order to asses whether a prior is appropriate <span id="id6">[<a class="reference internal" href="background.html#id22" title="Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. Visualization in bayesian workflow. Journal of the Royal Statistical Society Series A: Statistics in Society, 182(2):389–402, 2019.">Gabry <em>et al.</em>, 2019</a>]</span>, if observations are within the realm of possible model outcomes.</p>
<p>At this point of the workflow, no observed data was used in the model definition. In fact, probabilistic modelling could stop here: a model structure has been assumed, parameter probabilities have been chosen, and the prior predictive distribution can be computed for any prediction horizon. This is equivalent to predicting with an untrained model, while propagating the parameter uncertainty expressed by their prior <span class="math notranslate nohighlight">\(p(\theta)\)</span>.</p>
</section>
<section id="step-2-learning">
<h3>Step 2: learning<a class="headerlink" href="#step-2-learning" title="Link to this heading">#</a></h3>
<p>The target of Bayesian inference is to make probability statements about <span class="math notranslate nohighlight">\(\theta\)</span> given <span class="math notranslate nohighlight">\(y\)</span>. Once the full probability model has been specified (Eq. <a class="reference internal" href="#equation-model01">(2)</a>), conditioning on the known value of the data <span class="math notranslate nohighlight">\(y\)</span> using Bayes’ rule yields the posterior density:</p>
<div class="math notranslate nohighlight" id="equation-posterior1">
<span class="eqno">(4)<a class="headerlink" href="#equation-posterior1" title="Link to this equation">#</a></span>\[p(\theta|y) = \frac{p(\theta,y)}{p(y)}\]</div>
<div class="math notranslate nohighlight" id="equation-posterior2">
<span class="eqno">(5)<a class="headerlink" href="#equation-posterior2" title="Link to this equation">#</a></span>\[p(\theta|y) \propto p(\theta) p(y|\theta)\]</div>
<p>It is rarely possible to sample directly from the posterior distribution. Markov Chain Monte Carlo (MCMC) sampling methods are used to stochastically explore the typical set, i.e. the regions of parameter space which have a significant contribution to the desired expectations. Markov chains used in MCMC methods are designed so that their stationary distribution is the posterior distribution. If the chain is long enough, the generated chain <span class="math notranslate nohighlight">\(\left(\theta^{(1)},\dots,\theta^{(S)}\right)\)</span> provides samples from the typical set.</p>
<div class="math notranslate nohighlight" id="equation-thetas1">
<span class="eqno">(6)<a class="headerlink" href="#equation-thetas1" title="Link to this equation">#</a></span>\[\theta^{(s)} \sim p(\theta|y)\]</div>
<p>where each draw <span class="math notranslate nohighlight">\(\theta^{(s)}\)</span> contains a value for each of the <span class="math notranslate nohighlight">\(p\)</span> parameters of the model.</p>
<div class="math notranslate nohighlight" id="equation-thetas2">
<span class="eqno">(7)<a class="headerlink" href="#equation-thetas2" title="Link to this equation">#</a></span>\[\theta^{(s)} = \left(\theta_1,\dots,\theta_p\right)^{(s)}\]</div>
<p>This paper does not aim at explaining MCMC algorithms and their characteristics, but the reader is referred to <span id="id7">[<a class="reference internal" href="background.html#id23" title="Michael Betancourt. A conceptual introduction to hamiltonian monte carlo. arXiv preprint arXiv:1701.02434, 2017.">Betancourt, 2017</a>]</span> for a description of the state-of-the-art Hamiltonian Monte Carlo (HMC) algorithm and No-U-Turn Sampler (NUTS). Applications of HMC to the calibration of building energy models include whole building simulation <span id="id8">[<a class="reference internal" href="background.html#id24" title="Adrian Chong and Kathrin Menberg. Guidelines for the bayesian calibration of building energy models. Energy and Buildings, 174:527–547, 2018.">Chong and Menberg, 2018</a>]</span> and state-space models <span id="id9">[<a class="reference internal" href="background.html#id25" title="Lukas Lundström and Jan Akander. Bayesian calibration with augmented stochastic state-space models of district-heated multifamily buildings. Energies, 13(1):76, 2019.">Lundström and Akander, 2019</a>]</span>.</p>
<p>MCMC estimators converge to the true expectation values as the number of draws approaches infinity. In practice, diagnostics must be applied to check that the estimator follows the central limit theorem, which ensures that the estimator is unbiased after a finite number of draws. For that purpose it is first recommended to compute the (split-)<span class="math notranslate nohighlight">\(\hat{R}\)</span> statistic, or Gelman-Rubin statistic, with multiple chains initialized at different initial positions and split into two halves <span id="id10">[<a class="reference internal" href="background.html#id19" title="Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian data analysis. CRC press, 2013.">Gelman <em>et al.</em>, 2013</a>]</span>. The <span class="math notranslate nohighlight">\(\hat{R}\)</span> statistic measures for each scalar parameter, <span class="math notranslate nohighlight">\(\theta\)</span>, the ratio of samples variance within each chain <span class="math notranslate nohighlight">\(W\)</span> to the sample variance of all combined chains <span class="math notranslate nohighlight">\(B\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-rhat">
<span class="eqno">(8)<a class="headerlink" href="#equation-rhat" title="Link to this equation">#</a></span>\[\hat{R} = \sqrt{\frac{1}{W} \left(\frac{N-1}{N}W + \frac{1}{N}B \right)}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples. If the chains have not converged, <span class="math notranslate nohighlight">\(W\)</span> will underestimate the variance, since the individual chains have not had time to range all over the stationary distribution, and <span class="math notranslate nohighlight">\(B\)</span> will overestimate the variance, since the starting positions were chosen to be overdispersed.</p>
<p>Another important convergence diagnostics tool is the effective sample size (ESS), defined as:</p>
<div class="math notranslate nohighlight" id="equation-ess">
<span class="eqno">(9)<a class="headerlink" href="#equation-ess" title="Link to this equation">#</a></span>\[\text{ESS} = \frac{N}{1 + 2 \sum_{l=1}^{\infty} \rho_l}\]</div>
<p>with <span class="math notranslate nohighlight">\(\rho_l\)</span> the lag-<span class="math notranslate nohighlight">\(l\)</span> autocorrelation of a function <span class="math notranslate nohighlight">\(f\)</span> over the history of the Markov chain. The effective sample size is an estimate of the number of independent samples from the posterior distribution.</p>
<p>The diagnostic tools introduced in this section provide a principled workflow for reliable Bayesian inferences. They are readily available in most Bayesian computation libraries. Based on the recent improvements to the <span class="math notranslate nohighlight">\(\hat{R}\)</span> statistic <span id="id11">[<a class="reference internal" href="background.html#id26" title="Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. Rank-normalization, folding, and localization: an improved r for assessing convergence of mcmc (with discussion). Bayesian analysis, 16(2):667–718, 2021.">Vehtari <em>et al.</em>, 2021</a>]</span>, it is recommended to use the samples only if <span class="math notranslate nohighlight">\(\hat{R} &lt; 1.01\)</span> and <span class="math notranslate nohighlight">\(\text{ESS} &gt; 400\)</span>.</p>
</section>
<section id="step-3-model-checking-and-evaluation">
<h3>Step 3: model checking and evaluation<a class="headerlink" href="#step-3-model-checking-and-evaluation" title="Link to this heading">#</a></h3>
<p>The third step of Bayesian data analysis as formulated by <span id="id12">[<a class="reference internal" href="background.html#id19" title="Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian data analysis. CRC press, 2013.">Gelman <em>et al.</em>, 2013</a>]</span> is to evaluate the fit of the model and the implications of the resulting posterior distribution. This is done by drawing simulated values from the trained model and comparing them to the observed data.</p>
<figure class="align-center" id="workflowprediction">
<a class="reference internal image-reference" href="_images/302_prediction.png"><img alt="_images/302_prediction.png" src="_images/302_prediction.png" style="width: 500px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">The posterior predictive distribution are predictions by a model updated with the data</span><a class="headerlink" href="#workflowprediction" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The posterior predictive distribution is the distribution of the observable <span class="math notranslate nohighlight">\(\tilde{y}\)</span> conditioned on the observed data <span class="math notranslate nohighlight">\(y\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-posteriorpredictive">
<span class="eqno">(10)<a class="headerlink" href="#equation-posteriorpredictive" title="Link to this equation">#</a></span>\[p\left(\tilde{y}|y\right) = \int p\left(\tilde{y}|\theta\right) p\left(\theta | y\right) \mathrm{d}\theta\]</div>
<p>This definition is very similar to the prior predictive distribution given in Eq. \ref{eq:priorpredictive}, except that the prior <span class="math notranslate nohighlight">\(p(\theta)\)</span> has been replaced by the posterior <span class="math notranslate nohighlight">\(p(\theta|y)\)</span>. Similarly, it is simple to compute if the posterior has been approximated by an MCMC procedure: a finite number of parameter vectors <span class="math notranslate nohighlight">\(\theta^{(s)}\)</span> is drawn from the posterior distribution, and each of them is used to compute a model output <span class="math notranslate nohighlight">\(\tilde{y}^{(s)}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-ysample1">
<span class="eqno">(11)<a class="headerlink" href="#equation-ysample1" title="Link to this equation">#</a></span>\[\theta^{(s)} \sim p(\theta|y)\]</div>
<div class="math notranslate nohighlight" id="equation-ysample2">
<span class="eqno">(12)<a class="headerlink" href="#equation-ysample2" title="Link to this equation">#</a></span>\[\tilde{y}^{(s)} \sim p(y|\theta^{(s)})\]</div>
<p>where each draw <span class="math notranslate nohighlight">\(\tilde{y}^{(s)}\)</span> contains a value for each of the <span class="math notranslate nohighlight">\(N\)</span> data points of the prediction period.</p>
<div class="math notranslate nohighlight" id="equation-ysample3">
<span class="eqno">(13)<a class="headerlink" href="#equation-ysample3" title="Link to this equation">#</a></span>\[\tilde{y}^{(s)} = \left(\tilde{y}_1,\dots,\tilde{y}_N\right)^{(s)}\]</div>
<p>As a consequence, each individual data point <span class="math notranslate nohighlight">\(i\)</span> has a posterior predictive distribution approximated by the set <span class="math notranslate nohighlight">\(\tilde{y}_i^{(s)}\)</span>.</p>
<p>Much like in a traditional model fitting and validation workflow, proper model checking and validation should comprise two steps:</p>
<ul class="simple">
<li><p>First, checking the fit of the model with the training data itself through residual analysis. Should the model not match the data on which it was trained, it has little chance for out-of-sample scalability.</p></li>
<li><p>Then, assessing the model’s predictive performance outside of the training data, typically on a dedicated test dataset. The performance metrics used in this second step may then be used to compare and rank several models, and select the “best” one.</p></li>
</ul>
<section id="residual-analysis">
<h4>Residual analysis<a class="headerlink" href="#residual-analysis" title="Link to this heading">#</a></h4>
<p>Residual analysis is the process of checking the validity of modelling hypotheses. For instance, if the specification of the observational model states that errors are independent, identically distributed with zero mean and constant variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, then this hypothesis should be checked. One way to do it are the autocorrelation function (ACF) of one-step-ahead prediction residuals, or their cross-correlation function (CCF) with explanatory variables. Residual analysis is often confined to time series models, but is applicable as long as data are time indexed, even if the model does not formulate a dependency between consecutive observations.</p>
<p>The ACF of prediction residuals should have near-zero values for all lags above 1, to indicate the mutual independence of errors. If, for instance, the ACF has a significant non-zero value at lag 24 for a hourly prediction model, there is a chance that a daily occurring phenomenon has not been properly encoded in the model. A visual inspection of the ACF graph is a good diagnosis tool. On a more quantitative note, the Durbin-Watson statistic is used to detect autocorrelation in the residuals at lag 1, and the Ljung–Box test assesses autocorrelation up to a specified number of lags. The latter will be used below in the discussion of results.</p>
</section>
<section id="scoring-rules">
<h4>Scoring rules<a class="headerlink" href="#scoring-rules" title="Link to this heading">#</a></h4>
<p>To evaluate a model’s scalability, several metrics may calculated on a test dataset, separated from the training dataset.</p>
<p>The first category of metrics quantify a model’s prediction accuracy. The coefficient of variation of the root-mean-square error (CV(RMSE)) is a well-known measure of point estimates:</p>
<div class="math notranslate nohighlight" id="equation-cvrmse">
<span class="eqno">(14)<a class="headerlink" href="#equation-cvrmse" title="Link to this equation">#</a></span>\[\mathrm{CV(RMSE)} = \frac{1}{\bar{y}} \sqrt{\frac{1}{N}\sum_{i=1}^N\left(\tilde{y}_i-y_i\right)^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{y}_i\)</span> denotes a model prediction, <span class="math notranslate nohighlight">\(y_i\)</span> an observation and <span class="math notranslate nohighlight">\(\bar{y}\)</span> the average of all observations. The (normalized) Mean Bias Error and the Mean Absolute Error are alternatives to the CV(RMSE). However, they all only describe a model’s accuracy, and provide no insight on its precision. With a probabilistic model, these metrics may be calculated using the mean prediction, but more informative metrics are available.</p>
<figure class="align-center" id="metrics">
<a class="reference internal image-reference" href="_images/303_metrics.png"><img alt="_images/303_metrics.png" src="_images/303_metrics.png" style="width: 400px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Assessment probabilistic forecasts. 1) High accuracy, low precision; 2) Low accuracy, higher precision; 3) High accuracy and precision. The second situation is the least favorable: high confidence in an inaccurate solution.</span><a class="headerlink" href="#metrics" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Scoring rules <span id="id13">[<a class="reference internal" href="background.html#id27" title="Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359–378, 2007.">Gneiting and Raftery, 2007</a>]</span> are model evaluation metrics which assess probabilistic forecasts in terms of both accuracy and precision. They encourage forecasts whose precision match their accuracy: <a class="reference internal" href="#metrics"><span class="std std-numref">Fig. 17</span></a> illustrates the difference between several probabilistic forecasts, compared to a point estimate which can only be assessed by accuracy. The importance of prediction intervals was also underlined by <span id="id14">[<a class="reference internal" href="background.html#id28" title="Adrian Chong, Godfried Augenbroe, and Da Yan. Occupancy data at different spatial resolutions: building energy performance and model calibration. Applied Energy, 286:116492, 2021.">Chong <em>et al.</em>, 2021</a>]</span>, who used the Coverage Width-based Criterion metric to assess the reliability of predictions.</p>
<p>The Continuous Ranked Probability Score (CRPS) <span id="id15">[<a class="reference internal" href="background.html#id27" title="Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359–378, 2007.">Gneiting and Raftery, 2007</a>]</span> is appropriate to use when predictive distributions are expressed in terms of samples, originating from MCMC. Let <span class="math notranslate nohighlight">\(y_i\)</span> be an observation, and <span class="math notranslate nohighlight">\(F_i\)</span> the cumulative distribution function of the posterior prediction for this point <span class="math notranslate nohighlight">\(p\left(\tilde{y}_i|y\right)\)</span>. The CRPS between <span class="math notranslate nohighlight">\(y_i\)</span> and <span class="math notranslate nohighlight">\(F_i\)</span> is defined by:</p>
<div class="math notranslate nohighlight" id="equation-crps1">
<span class="eqno">(15)<a class="headerlink" href="#equation-crps1" title="Link to this equation">#</a></span>\[\mathrm{CRPS}(F_i, y_i) = -\int_{-\infty}^{\infty} \left( F(z) - \mathcal{H}\left(z\geq y_i\right)\right)^2 \mathrm{d}z\]</div>
<div class="math notranslate nohighlight" id="equation-crps2">
<span class="eqno">(16)<a class="headerlink" href="#equation-crps2" title="Link to this equation">#</a></span>\[\mathrm{CRPS}(F_i, y_i) = -\int_{-\infty}^{y_i} F(z)^2 \mathrm{d}z \; -  \; \int_{y_i}^{\infty} \left( F(z) - 1\right)^2 \mathrm{d}z\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is the Heaviside function which takes a value of 1 if its argument is positive, 0 otherwise. Schematically speaking, the CRPS is the sum of two (squared) areas: between 0 and <span class="math notranslate nohighlight">\(F_i\)</span> for posterior values below <span class="math notranslate nohighlight">\(y_i\)</span>, and between <span class="math notranslate nohighlight">\(F_i\)</span> and 1 for values above <span class="math notranslate nohighlight">\(y_i\)</span>. A low CRPS is obtained with either a high precision or accuracy, or both (the cumulative distribution varies “quickly” between 0 and 1 near the target value).</p>
<p>The total CRPS of a test dataset is then the sum of individual CRPS values at each data point.</p>
</section>
</section>
</section>
<section id="model-comparison-and-cross-validation">
<h2>Model comparison and cross-validation<a class="headerlink" href="#model-comparison-and-cross-validation" title="Link to this heading">#</a></h2>
<p>Once a model has passed the validation criteria, its structure may be assumed sufficient to explain the main mechanics of the data generating process. However, this does not ensure that this model is the most appropriate one to draw inferences from, or to use for future predictions.</p>
<p>On one hand, residual analysis imposes a lower bound on the necessary model complexity to capture the data-generating process; on the other hand, an upper bound on model complexity is imposed by the risk of overfitting: a model with too many degrees of freedom will fit the training data very well, but will poorly extrapolate to new data, because it will reproduce specific patterns caused by local errors.</p>
<p>Model selection criteria are designed to help comparing several models, not just based on their fit with training data, but on an estimation of their prediction accuracy with new data. These criteria often reward models that offer a good compromise between simplicity and accuracy. There are several options:</p>
<ul class="simple">
<li><p>Computing the above model assessment metrics on a test dataset, separate from the training dataset, gives an estimate of each model’s scalability. However, this ranking still occurs in specific conditions given by the test dataset.</p></li>
<li><p>Cross-validation is similar to this principle: the training data is split into several portions, each of which serves as test data for a model trained on all other portions. <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation therefore implies fitting a model <span class="math notranslate nohighlight">\(k\)</span> times. Leave-one-out (LOO) cross-validation is the particular case where only one observation is left out of the training dataset.</p></li>
</ul>
<p>Exact LOO cross-validation is very costly, since it requires training the model as many times as there are observations, each time leaving out one observation. Instead, Pareto-smoothed importance sampling leave-one-out (PSIS-LOO) cross-validation <span id="id16">[<a class="reference internal" href="background.html#id29" title="Aki Vehtari, Andrew Gelman, and Jonah Bagry. Practical bayesian model evaluation using leave-one-out cross-validation and waic. Statistics and Computing, 27:1413–1432, Aug 2016.">Vehtari <em>et al.</em>, 2016</a>]</span> approximates the LOO estimate, using the pointwise log-likelihood values computed from samples of the posterior. This method can be considered the state-of-the-art Bayesian criterion of model comparison and selection. It does not require nested models, has a fast computation time and is asymptotically equivalent to the Widely Applicable Information Criterion (WAIC) <span id="id17">[<a class="reference internal" href="background.html#id30" title="Sumio Watanabe and Manfred Opper. Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory. Journal of machine learning research, 2010.">Watanabe and Opper, 2010</a>]</span>.</p>
<p>The expected log pointwise predictive density for a new dataset (elpd) is a measure of predictive accuracy for the <span class="math notranslate nohighlight">\(N\)</span> data points of a given dataset, taken one at a time. The Bayesian LOO estimate of out-of-sample predictive fit is:</p>
<div class="math notranslate nohighlight" id="equation-elpd1">
<span class="eqno">(17)<a class="headerlink" href="#equation-elpd1" title="Link to this equation">#</a></span>\[\mathrm{elpd}_\mathrm{loo} = \sum_{i=1}^N \mathrm{log}p(y_i|y_{-i})\]</div>
<div class="math notranslate nohighlight" id="equation-elpd2">
<span class="eqno">(18)<a class="headerlink" href="#equation-elpd2" title="Link to this equation">#</a></span>\[p(y_i|y_{-i}) = \int p(y_i|\theta)p(\theta|y_{-i})\mathrm{d}\theta\]</div>
<p>is the leave-one-out predictive density of data point <span class="math notranslate nohighlight">\(y_i\)</span>, given the dataset minus the <span class="math notranslate nohighlight">\(i\)</span>th data point, denoted <span class="math notranslate nohighlight">\(y_{-i}\)</span>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="modelling.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Simplified building energy modelling</p>
      </div>
    </a>
    <a class="right-next"
       href="b01_linearregression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Linear regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-a-bayesian-approach">Motivation for a Bayesian approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Workflow</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-setting-up-a-probability-model">Step 1: setting up a probability model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-learning">Step 2: learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-checking-and-evaluation">Step 3: model checking and evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-analysis">Residual analysis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scoring-rules">Scoring rules</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparison-and-cross-validation">Model comparison and cross-validation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Simon Rouchier
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>